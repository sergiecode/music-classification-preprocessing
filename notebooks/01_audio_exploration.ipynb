{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f755d4",
   "metadata": {},
   "source": [
    "# Audio Data Exploration\n",
    "\n",
    "This notebook demonstrates how to explore and analyze audio data using the music preprocessing pipeline.\n",
    "\n",
    "## Topics Covered:\n",
    "- Loading and visualizing audio files\n",
    "- Basic audio statistics and properties\n",
    "- Audio quality validation\n",
    "- Preprocessing audio for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f02e2af",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our preprocessing modules\n",
    "from audio_loader import AudioLoader\n",
    "from utils.audio_utils import validate_audio_quality, preprocess_audio_standard\n",
    "from utils.visualization import plot_waveform, create_audio_analysis_report\n",
    "\n",
    "print(\"Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d34728",
   "metadata": {},
   "source": [
    "## Loading Audio Files\n",
    "\n",
    "Let's start by loading an audio file and examining its properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8f31df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize audio loader\n",
    "loader = AudioLoader(target_sr=22050, mono=True, normalize=True)\n",
    "\n",
    "# Example: Load an audio file (replace with your audio file path)\n",
    "# audio_file = \"../data/examples/sample_song.mp3\"\n",
    "# \n",
    "# For demonstration, we'll create a synthetic audio signal\n",
    "# In practice, you would load a real audio file\n",
    "\n",
    "# Create a synthetic audio signal for demonstration\n",
    "duration = 5.0  # seconds\n",
    "sample_rate = 22050\n",
    "t = np.linspace(0, duration, int(duration * sample_rate))\n",
    "\n",
    "# Create a complex signal with multiple frequencies and some noise\n",
    "audio_data = (\n",
    "    0.5 * np.sin(2 * np.pi * 440 * t) +  # A4 note\n",
    "    0.3 * np.sin(2 * np.pi * 880 * t) +  # A5 note\n",
    "    0.2 * np.sin(2 * np.pi * 220 * t) +  # A3 note\n",
    "    0.1 * np.random.randn(len(t))        # Some noise\n",
    ")\n",
    "\n",
    "print(f\"Audio loaded:\")\n",
    "print(f\"  Duration: {len(audio_data) / sample_rate:.2f} seconds\")\n",
    "print(f\"  Sample rate: {sample_rate} Hz\")\n",
    "print(f\"  Number of samples: {len(audio_data)}\")\n",
    "print(f\"  Data type: {audio_data.dtype}\")\n",
    "print(f\"  Min amplitude: {np.min(audio_data):.4f}\")\n",
    "print(f\"  Max amplitude: {np.max(audio_data):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ed550",
   "metadata": {},
   "source": [
    "## Audio Visualization\n",
    "\n",
    "Let's visualize the audio waveform to understand its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0812b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the full waveform\n",
    "plot_waveform(audio_data, sample_rate, title=\"Complete Audio Waveform\")\n",
    "\n",
    "# Plot a zoomed-in section to see more detail\n",
    "start_sample = int(1.0 * sample_rate)  # Start at 1 second\n",
    "end_sample = int(2.0 * sample_rate)    # End at 2 seconds\n",
    "audio_segment = audio_data[start_sample:end_sample]\n",
    "\n",
    "plot_waveform(audio_segment, sample_rate, title=\"Audio Waveform (1-2 seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c07616",
   "metadata": {},
   "source": [
    "## Audio Quality Validation\n",
    "\n",
    "Before processing, let's validate the audio quality to identify potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae0cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate audio quality\n",
    "quality_results = validate_audio_quality(audio_data, sample_rate)\n",
    "\n",
    "print(\"Audio Quality Assessment:\")\n",
    "print(f\"  Overall Quality Score: {quality_results['quality_score']:.2f}/1.0\")\n",
    "print(f\"  Duration OK: {quality_results['duration_ok']} ({quality_results['duration']:.2f}s)\")\n",
    "print(f\"  Clipping OK: {quality_results['clipping_ok']} ({quality_results['clipping_ratio']:.4f} ratio)\")\n",
    "print(f\"  Silence OK: {quality_results['silence_ok']} ({quality_results['silence_ratio']:.4f} ratio)\")\n",
    "print(f\"  Dynamic Range OK: {quality_results['dynamic_range_ok']} ({quality_results['dynamic_range']:.4f})\")\n",
    "print(f\"  DC Bias OK: {quality_results['dc_bias_ok']} ({quality_results['dc_bias']:.4f})\")\n",
    "print(f\"  Overall Assessment: {'PASS' if quality_results['overall_ok'] else 'FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b856fb2",
   "metadata": {},
   "source": [
    "## Audio Statistics\n",
    "\n",
    "Let's compute some basic statistics about our audio signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33461634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute basic statistics\n",
    "print(\"Audio Statistics:\")\n",
    "print(f\"  Mean: {np.mean(audio_data):.6f}\")\n",
    "print(f\"  Standard Deviation: {np.std(audio_data):.6f}\")\n",
    "print(f\"  RMS Energy: {np.sqrt(np.mean(audio_data**2)):.6f}\")\n",
    "print(f\"  Peak Amplitude: {np.max(np.abs(audio_data)):.6f}\")\n",
    "print(f\"  Zero Crossings: {np.sum(np.diff(np.sign(audio_data)) != 0)}\")\n",
    "\n",
    "# Compute spectral statistics using librosa\n",
    "import librosa\n",
    "\n",
    "# Spectral centroid (brightness)\n",
    "spectral_centroids = librosa.feature.spectral_centroid(y=audio_data, sr=sample_rate)[0]\n",
    "print(f\"  Spectral Centroid (mean): {np.mean(spectral_centroids):.2f} Hz\")\n",
    "\n",
    "# Spectral rolloff\n",
    "spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_data, sr=sample_rate)[0]\n",
    "print(f\"  Spectral Rolloff (mean): {np.mean(spectral_rolloff):.2f} Hz\")\n",
    "\n",
    "# Zero crossing rate\n",
    "zcr = librosa.feature.zero_crossing_rate(audio_data)[0]\n",
    "print(f\"  Zero Crossing Rate (mean): {np.mean(zcr):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47eb065",
   "metadata": {},
   "source": [
    "## Audio Preprocessing\n",
    "\n",
    "Let's apply standard preprocessing steps to prepare the audio for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5378b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standard preprocessing\n",
    "processed_audio, processed_sr = preprocess_audio_standard(\n",
    "    audio_data, \n",
    "    sample_rate,\n",
    "    target_sr=22050,\n",
    "    normalize_method=\"peak\",\n",
    "    trim_silence_flag=True\n",
    ")\n",
    "\n",
    "print(\"Preprocessing Results:\")\n",
    "print(f\"  Original length: {len(audio_data)} samples ({len(audio_data)/sample_rate:.2f}s)\")\n",
    "print(f\"  Processed length: {len(processed_audio)} samples ({len(processed_audio)/processed_sr:.2f}s)\")\n",
    "print(f\"  Sample rate: {processed_sr} Hz\")\n",
    "\n",
    "# Compare original vs processed\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Original audio\n",
    "time_orig = np.linspace(0, len(audio_data) / sample_rate, len(audio_data))\n",
    "ax1.plot(time_orig, audio_data, alpha=0.8)\n",
    "ax1.set_title('Original Audio')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Processed audio\n",
    "time_proc = np.linspace(0, len(processed_audio) / processed_sr, len(processed_audio))\n",
    "ax2.plot(time_proc, processed_audio, alpha=0.8, color='orange')\n",
    "ax2.set_title('Processed Audio')\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41204f13",
   "metadata": {},
   "source": [
    "## Frequency Domain Analysis\n",
    "\n",
    "Let's examine the frequency content of our audio signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8880e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute FFT for frequency analysis\n",
    "fft = np.fft.fft(processed_audio)\n",
    "fft_magnitude = np.abs(fft)\n",
    "fft_freq = np.fft.fftfreq(len(processed_audio), 1/processed_sr)\n",
    "\n",
    "# Only plot positive frequencies\n",
    "positive_freq_idx = fft_freq >= 0\n",
    "fft_freq_positive = fft_freq[positive_freq_idx]\n",
    "fft_magnitude_positive = fft_magnitude[positive_freq_idx]\n",
    "\n",
    "# Plot frequency spectrum\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fft_freq_positive, fft_magnitude_positive)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.title('Frequency Spectrum')\n",
    "plt.xlim(0, 2000)  # Focus on lower frequencies\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Mark the fundamental frequencies we used\n",
    "plt.axvline(x=220, color='red', linestyle='--', alpha=0.7, label='A3 (220 Hz)')\n",
    "plt.axvline(x=440, color='green', linestyle='--', alpha=0.7, label='A4 (440 Hz)')\n",
    "plt.axvline(x=880, color='blue', linestyle='--', alpha=0.7, label='A5 (880 Hz)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find dominant frequencies\n",
    "peak_indices = np.argsort(fft_magnitude_positive)[-10:]  # Top 10 peaks\n",
    "dominant_freqs = fft_freq_positive[peak_indices]\n",
    "\n",
    "print(\"Top 10 Dominant Frequencies:\")\n",
    "for i, freq in enumerate(sorted(dominant_freqs[dominant_freqs > 0])[:10]):\n",
    "    print(f\"  {i+1}. {freq:.1f} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e44123",
   "metadata": {},
   "source": [
    "## Working with Real Audio Files\n",
    "\n",
    "Here's how you would work with real audio files from your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of working with real audio files\n",
    "# Uncomment and modify the following code to work with your audio files\n",
    "\n",
    "# # Define path to your audio files\n",
    "# audio_dir = Path(\"../data/raw_audio\")\n",
    "# \n",
    "# # Get list of audio files\n",
    "# if audio_dir.exists():\n",
    "#     audio_files = list(audio_dir.glob(\"*.mp3\")) + list(audio_dir.glob(\"*.wav\"))\n",
    "#     print(f\"Found {len(audio_files)} audio files\")\n",
    "#     \n",
    "#     # Load and analyze the first file\n",
    "#     if audio_files:\n",
    "#         first_file = audio_files[0]\n",
    "#         print(f\"Analyzing: {first_file.name}\")\n",
    "#         \n",
    "#         # Load audio\n",
    "#         audio_data, sr = loader.load_audio(first_file)\n",
    "#         \n",
    "#         # Get file info\n",
    "#         file_info = loader.get_audio_info(first_file)\n",
    "#         print(f\"Duration: {file_info['duration']:.2f} seconds\")\n",
    "#         print(f\"Sample rate: {file_info['sample_rate']} Hz\")\n",
    "#         print(f\"Channels: {file_info['channels']}\")\n",
    "#         \n",
    "#         # Validate quality\n",
    "#         quality = validate_audio_quality(audio_data, sr)\n",
    "#         print(f\"Quality score: {quality['quality_score']:.2f}\")\n",
    "#         \n",
    "#         # Create visualization\n",
    "#         plot_waveform(audio_data, sr, title=f\"Waveform: {first_file.name}\")\n",
    "# else:\n",
    "#     print(\"Audio directory not found. Create ../data/raw_audio/ and add some audio files.\")\n",
    "\n",
    "print(\"Ready to analyze real audio files!\")\n",
    "print(\"To use this notebook with your audio files:\")\n",
    "print(\"1. Create a 'data/raw_audio' directory\")\n",
    "print(\"2. Add some audio files (.mp3, .wav, etc.)\")\n",
    "print(\"3. Uncomment and run the code above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb24320",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've explored:\n",
    "- How to load and validate audio files\n",
    "- Basic audio statistics and properties\n",
    "- Audio preprocessing techniques\n",
    "- Frequency domain analysis\n",
    "- Visualization of audio data\n",
    "\n",
    "This foundational understanding of audio data will help you in the next steps of feature extraction and model preparation.\n",
    "\n",
    "## Next Steps\n",
    "- Check out `02_feature_analysis.ipynb` for feature extraction\n",
    "- Explore `03_spectrogram_visualization.ipynb` for spectrogram analysis\n",
    "- Start building your dataset using the batch processing tools"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
